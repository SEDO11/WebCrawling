{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ffb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef35d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a430b329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 터미널에서 입력하세요 : 박동진\n",
      "https://www.google.com/search?q=%EB%B0%95%EB%8F%99%EC%A7%84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euihan Lee\\AppData\\Local\\Temp\\ipykernel_17584\\73155062.py:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\\\Users\\\\Euihan Lee\\\\[Challenge Python]\\\\chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "박동진 (@park_hpbm50) • Instagram photos and videos\n",
      "https://www.instagram.com/park_hpbm50/\n",
      "\n",
      "박동진 - 장치기술 엔지니어 - SK Energy International | LinkedIn\n",
      "https://kr.linkedin.com/in/%EB%8F%99%EC%A7%84-%EB%B0%95-aa115aa8\n",
      "\n",
      "박동진(朴東鎭) - 한국민족문화대백과사전\n",
      "http://encykorea.aks.ac.kr/Contents/Item/E0072520\n",
      "\n",
      "박동진 | 다음스포츠\n",
      "https://sports.daum.net/player/kl/1218663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "baseurl = 'https://www.google.com/search?q='\n",
    "pluseurl = input('검색어를 터미널에서 입력하세요 : ')\n",
    "url = baseurl + urllib.parse.quote_plus(pluseurl)\n",
    "\n",
    "print(url)\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\Euihan Lee\\\\[Challenge Python]\\\\chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "r = soup.select('.tF2Cxc')\n",
    "\n",
    "print(type(r))\n",
    "\n",
    "for i in r :  \n",
    "    print(i.select_one('.LC20lb.MBeuO.DKV0Md').text)\n",
    "    print(i.a.attrs['href'])\n",
    "    print()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b82d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 터미널에서 입력하세요 : 박동진\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m pluseurl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m검색어를 터미널에서 입력하세요 : \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m backurl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A1\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A1\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartDate\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1975-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m2C\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendDate\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3A\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1999-12-31\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m7D\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m url \u001b[38;5;241m=\u001b[39m baseurl \u001b[38;5;241m+\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote_plus(pluseurl) \u001b[38;5;241m+\u001b[39m backurl\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[0;32m     11\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEuihan Lee\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m[Challenge Python]\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mchromedriver.exe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "\n",
    "baseurl = 'https://newslibrary.naver.com/search/searchByKeyword.naver#%7B%22mode%22%3A1%2C%22sort%22%3A0%2C%22trans%22%3A%221%22%2C%22pageSize%22%3A10%2C%22keyword%22%3A%22'\n",
    "pluseurl = input('검색어를 터미널에서 입력하세요 : ')\n",
    "backurl = '\"%2C\"status\"%3A\"success\"%2C\"startIndex\"%3A1%2C\"page\"%3A1%2C\"startDate\"%3A\"1975-01-01\"%2C\"endDate\"%3A\"1999-12-31\"%7D'\n",
    "url = baseurl + urllib.parse.quote_plus(pluseurl) + backurl\n",
    "\n",
    "print(url)\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\Euihan Lee\\\\[Challenge Python]\\\\chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "r = soup.select('.data')\n",
    "\n",
    "print(type(r))\n",
    "\n",
    "for i in r :  \n",
    "    print(i.a.attrs['href'])\n",
    "    print()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ad270f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 터미널에서 입력하세요 : 박동진\n",
      "https://newslibrary.naver.com/search/searchByKeyword.naver#%7B%22mode%22%3A1%2C%22sort%22%3A0%2C%22trans%22%3A%221%22%2C%22pageSize%22%3A10%2C%22keyword%22%3A%22%EB%B0%95%EB%8F%99%EC%A7%84\"%2C\"status\"%3A\"success\"%2C\"startIndex\"%3A1%2C\"page\"%3A1%2C\"startDate\"%3A\"1975-01-01\"%2C\"endDate\"%3A\"1999-12-31\"%7D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euihan Lee\\AppData\\Local\\Temp\\ipykernel_17584\\3897362594.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\\\Users\\\\Euihan Lee\\\\[Challenge Python]\\\\chromedriver.exe')\n"
     ]
    },
    {
     "ename": "SelectorSyntaxError",
     "evalue": "Tag name found at position 15 instead of at the start\n  line 1:\nnclicks-th2_all*a.tit\n               ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     15\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnclicks-th2_all*a.tit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(r))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r :\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py:1973\u001b[0m, in \u001b[0;36mTag.select\u001b[1;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soupsieve \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot execute CSS selectors because the soupsieve package is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m     )\n\u001b[1;32m-> 1973\u001b[0m results \u001b[38;5;241m=\u001b[39m soupsieve\u001b[38;5;241m.\u001b[39mselect(selector, \u001b[38;5;28mself\u001b[39m, namespaces, limit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# We do this because it's more consistent and because\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# ResultSet.__getattr__ has a helpful error message.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ResultSet(\u001b[38;5;28;01mNone\u001b[39;00m, results)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soupsieve\\__init__.py:144\u001b[0m, in \u001b[0;36mselect\u001b[1;34m(select, tag, namespaces, limit, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[0;32m    133\u001b[0m     select: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    134\u001b[0m     tag: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs4.Tag\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs4.Tag\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124;03m\"\"\"Select the specified tags.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m(select, namespaces, flags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mselect(tag, limit)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soupsieve\\__init__.py:67\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, namespaces, flags, custom, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot process \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument on a compiled selector list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pattern\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_css_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py:218\u001b[0m, in \u001b[0;36m_cached_css_compile\u001b[1;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"Cached CSS compile.\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m custom_selectors \u001b[38;5;241m=\u001b[39m process_custom(custom)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cm\u001b[38;5;241m.\u001b[39mSoupSieve(\n\u001b[0;32m    217\u001b[0m     pattern,\n\u001b[1;32m--> 218\u001b[0m     \u001b[43mCSSParser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_selectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    223\u001b[0m     namespaces,\n\u001b[0;32m    224\u001b[0m     custom,\n\u001b[0;32m    225\u001b[0m     flags\n\u001b[0;32m    226\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py:1159\u001b[0m, in \u001b[0;36mCSSParser.process_selectors\u001b[1;34m(self, index, flags)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_selectors\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ct\u001b[38;5;241m.\u001b[39mSelectorList:\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;124;03m\"\"\"Process selectors.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_selectors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py:1037\u001b[0m, in \u001b[0;36mCSSParser.parse_selectors\u001b[1;34m(self, iselector, index, flags)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_selector:\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SelectorSyntaxError(\n\u001b[0;32m   1038\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag name found at position \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead of at the start\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern,\n\u001b[0;32m   1040\u001b[0m             m\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1041\u001b[0m         )\n\u001b[0;32m   1042\u001b[0m     has_selector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_tag_pattern(sel, m, has_selector)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mSelectorSyntaxError\u001b[0m: Tag name found at position 15 instead of at the start\n  line 1:\nnclicks-th2_all*a.tit\n               ^"
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "\n",
    "baseurl = 'https://newslibrary.naver.com/search/searchByKeyword.naver#%7B%22mode%22%3A1%2C%22sort%22%3A0%2C%22trans%22%3A%221%22%2C%22pageSize%22%3A10%2C%22keyword%22%3A%22'\n",
    "pluseurl = input('검색어를 터미널에서 입력하세요 : ')\n",
    "backurl = '\"%2C\"status\"%3A\"success\"%2C\"startIndex\"%3A1%2C\"page\"%3A1%2C\"startDate\"%3A\"1975-01-01\"%2C\"endDate\"%3A\"1999-12-31\"%7D'\n",
    "url = baseurl + urllib.parse.quote_plus(pluseurl) + backurl\n",
    "\n",
    "print(url)\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\Euihan Lee\\\\[Challenge Python]\\\\chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "r = soup.select('nclicks-th2_all*a.tit')\n",
    "\n",
    "print(type(r))\n",
    "\n",
    "for i in r :\n",
    "    time.sleep(3)\n",
    "    print(i.attrs[\"title\"].text)\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "baseurl = 'https://newslibrary.naver.com/search/searchByKeyword.naver#%7B%22mode%22%3A1%2C%22sort%22%3A0%2C%22trans%22%3A%221%22%2C%22pageSize%22%3A10%2C%22keyword%22%3A%22'\n",
    "pluseurl = input('검색어를 터미널에서 입력하세요 : ')\n",
    "backurl = '\"%2C\"status\"%3A\"success\"%2C\"startIndex\"%3A1%2C\"page\"%3A1%2C\"startDate\"%3A\"1975-01-01\"%2C\"endDate\"%3A\"1999-12-31\"%7D'\n",
    "url = baseurl + urllib.parse.quote_plus(pluseurl) + backrul\n",
    "\n",
    "# 1. 웹에서 데이터 가져오기 : 네이버TV 사이트\n",
    "url = ''\n",
    "raw = requests.get(\"https://newslibrary.naver.com/search/searchByKeyword.naver#%7B%22mode%22%3A1%2C%22sort%22%3A0%2C%22trans%22%3A1%2C%22pageSize%22%3A10%2C%22keyword%22%3A%22%EB%B0%95%EB%8F%99%EC%A7%84%22%2C%22status%22%3A%22success%22%2C%22startIndex%22%3A1%2C%22page%22%3A1%2C%22startDate%22%3A%221920-03-05%22%2C%22endDate%22%3A%221999-12-31%22%7D\")\n",
    "raw.encoding='utf-8'\n",
    "\n",
    "# 2. 웹사이트의 HTML 소스코드 Parsing\n",
    "html = BeautifulSoup(raw.text, \"html.parser\")\n",
    "\n",
    "# 1. 컨테이너 선택 : select 함수\n",
    "container = html.select(\"onclick\")\n",
    "\n",
    "#'''\n",
    "#container[0] : 1위 영상의 컨테이너\n",
    "#container[1] : 2위 영상의 컨테이너\n",
    "#container[2] : 3위 영상의 컨테이너\n",
    "# 즉 se<a class=\"nclicks-th2_all*a.tit\" onclick=\"return openViewPopup(this);\" href=\"/viewer/index.naver?articleId=1984082500239101001&editNo=1&printCount=1&p…ishDate=1984-08-25&officeId=00023&pageNo=1&printNo=19505&publishType=00010\" title=\"마두라 油田(유전) 개발 성공 42만배럴 첫 導入(도입)\">…</a>lect 함수는 'div.data'라는 선택자를 갖는 정보를 각 순서대로 리스트 형태로 저장함'''\n",
    "\n",
    "# 2. 각 컨테이너별 데이터 수집 : select_one 함수\n",
    "# 반복문을 이용해 각 컨테이너별로 데이터를 수집한다.\n",
    "for con in container:\n",
    "    title = con.select_one(\"a.nclicks-th2_all*a.tit\").text.strip() #제목\n",
    "    summ = con.select_one(\"strong.highlight\").text.strip() #채널\n",
    "    print(title, \"/\", summ, \"/\")\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 컨테이너 선택 : select 함수\n",
    "container = html.select(\"div.data\")\n",
    "\n",
    "#'''\n",
    "#container[0] : 1위 영상의 컨테이너\n",
    "#container[1] : 2위 영상의 컨테이너\n",
    "#container[2] : 3위 영상의 컨테이너\n",
    "# 즉 select 함수는 'div.data'라는 선택자를 갖는 정보를 각 순서대로 리스트 형태로 저장함'''\n",
    "\n",
    "# 2. 각 컨테이너별 데이터 수집 : select_one 함수\n",
    "# 반복문을 이용해 각 컨테이너별로 데이터를 수집한다.\n",
    "for con in container:\n",
    "    title = con.select_one(\"n#searchlist > ul > li:nth-child(i) > div.data > h3 > a\").text.strip() #제목\n",
    "    summ = con.select_one(\"#searchlist > ul > li:nth-child(i) > div.data > div\").text.strip() #채널\n",
    "    print(title, \"/\", summ, \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "raw = requests.get(\"https://tv.naver.com/r\")\n",
    "html = BeautifulSoup(raw.text, \"html.parser\")\n",
    "\n",
    "# 각 데이터를 담을 list 생성\n",
    "title = []\n",
    "chn = []\n",
    "hit = []\n",
    "like = []\n",
    "\n",
    "container = html.select(\"div.inner\")\n",
    "for con in container:\n",
    "    t = con.select_one(\"dt.title\").text.strip()\t#제목\n",
    "    c = con.select_one(\"dd.chn\").text.strip()\t#채널\n",
    "    h = con.select_one(\"span.hit\").text.strip() #조회수\n",
    "    l = con.select_one(\"span.like\").text.strip()\t#좋아요수\n",
    "    \n",
    "    title.append(t)\n",
    "    chn.append(c)\n",
    "    hit.append(h)\n",
    "    like.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver.get(\"https://newslibrary.naver.com/search/searchByKeyword.naver\")\n",
    "\n",
    "searchbox = driver.find_element_by_css_selector(\"input#search_txt.input_txt\")\n",
    "searchbox.send_keys(input('검색어 찾기: '))\n",
    "\n",
    "searchbutton = driver.find_element_by_css_selector(\"input#btn_search.nclicks-sc2.sch\")\n",
    "searchbutton.click()\n",
    "\n",
    "for i in range(999):\n",
    "    time.sleep(3)\n",
    "    \n",
    "    stores = driver.find_elements_by_css_selector(\"div.searchlist\")\n",
    "    \n",
    "    for s in stores:\n",
    "        title = s.find_element_by_css_selector(\"h3.section-result-title\").text\n",
    "        \n",
    "        try:\n",
    "            score = s.find_element_by_css_selector(\"span.cards-rating-score\").text\n",
    "        except:\n",
    "            score = \"평점없음\"\n",
    "        \n",
    "        addr = s.find_element_by_css_selector(\"span.section-result-location\").text\n",
    "        \n",
    "        print(title, \"/\", score, \"/\", addr)\n",
    "    \n",
    "    try:\n",
    "        nextpage = driver.find_element_by_css_selector(\"button#n7lv7yjyC35__section-pagination-button-next\")\n",
    "        nextpage.click()\n",
    "    except:\n",
    "        print(\"데이터 수집 완료.\")\n",
    "        break\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('', 'r')\n",
    "text = file.read()\n",
    "print(text)\n",
    "\n",
    "world_list = text.split()\n",
    "\n",
    "count_list = [ ]\n",
    "for word in word_list:\n",
    "    count = world_list.count(word)\n",
    "    count_list.append([word, count])\n",
    "    \n",
    "sorted_list = sorted(count_list, key=lambda x: x[1], reverse = True)\n",
    "\n",
    "word_dict = { }\n",
    "for word, frequency in sorted_list:\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = frequency\n",
    "        print(word, frequency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
